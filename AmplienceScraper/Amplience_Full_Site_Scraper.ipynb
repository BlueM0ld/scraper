{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56fe6634",
   "metadata": {},
   "source": [
    "# Amplience Full Site Scraper \n",
    "\n",
    "***Work in progress, the current solution is not optimised and needs to be refactored into functions***\n",
    "\n",
    "Before running this file please install the below libraies \n",
    "\n",
    "- Beautiful soup\n",
    "- requests\n",
    "\n",
    "The way this file works in by starting the scrapping from the Documentation homepage. We scrap from the sidebar menu and try to grab every single link avaliable. The rest of the code is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fdeec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3160ca7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lucsnype/opt/anaconda3/lib/python3.9/site-packages (from requests) (1.26.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16433e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://amplience.com/developers/docs/\"\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768cb74e",
   "metadata": {},
   "source": [
    "# Stable scrapper\n",
    "\n",
    "The below function is a test scrapper that just scraps from the start page of each of the sections within the documentation. It's the most stable version of the scrapper and should run completely fine with no faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc88770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/developers/docs/\n",
      "/developers/docs/start/\n",
      "/developers/docs/concepts/\n",
      "/developers/docs/schema-reference/\n",
      "/developers/docs/apis/\n",
      "/developers/docs/integrations/\n",
      "/developers/docs/dev-tools/\n",
      "/developers/docs/technologies/\n",
      "/developers/docs/release-notes/\n",
      "/developers/docs/knowledge-center/\n",
      "/developers/docs/user-guides/\n"
     ]
    }
   ],
   "source": [
    "for c in soup.body.findAll('ul', {'class':'theme-doc-sidebar-menu menu__list'}):\n",
    "    #print(c.get('href'))\n",
    "    for d in c.findAll('a',{'class':'menu__link'}):\n",
    "            print(d.get('href'))\n",
    "            \n",
    "            new_URL = d.get('href')\n",
    "            URL_2 = \"https://amplience.com\" + new_URL\n",
    "            r2 = requests.get(URL_2)\n",
    "            soup1 = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "            #print(soup.prettify())\n",
    "\n",
    "            #Now remove the script & then palce in files \n",
    "            for script in soup1([\"script\", \"style\"]):\n",
    "                script.extract()    # rip it out\n",
    "\n",
    "            # get text\n",
    "            text = soup1.get_text()\n",
    "\n",
    "            # break into lines and remove leading and trailing space on each\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            # break multi-headlines into a line each\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            # drop blank lines\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "            # convert into JSON:\n",
    "\n",
    "            fileName = new_URL.replace('/','')\n",
    "\n",
    "            y = json.dumps(text)\n",
    "\n",
    "            with open(fileName + 'json_data.json', 'w') as outfile:\n",
    "                outfile.write(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a389bb6",
   "metadata": {},
   "source": [
    "# Unstable Solution\n",
    "\n",
    "This solution tries to grab the links within then menu bar then the rest of the links within that page. \n",
    "\n",
    "The solution does not currently work completely there is a already a output saved in the directory under **Unstable solution_First output** \n",
    "\n",
    "There is a chance for the requests to time out and fail within this solution due to how many requests are sent to amiplience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb21cc1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in soup.body.findAll('ul', {'class':'theme-doc-sidebar-menu menu__list'}):\n",
    "    for f in e.findAll('a',{'class':'menu__link'}):\n",
    "        #r3 = requests.get('https://amplience.com/'+ new_URL3)\n",
    "        #soup3 = BeautifulSoup(r3.content, 'html.parser')\n",
    "\n",
    "        #Here we attempt to grab each of the links within the current page - Only grabs User guides currently\n",
    "        for e in soup.findAll('ul', {'class':'theme-doc-sidebar-menu menu__list'}):\n",
    "            for f in e.findAll('a',{'class':'menu__link'}):\n",
    "                #Here we get the URL on the Menu bar on the website \n",
    "                \n",
    "                new_URL3 = f.get('href')\n",
    "                URL_3 = \"https://amplience.com\" + new_URL3\n",
    "                \n",
    "                r3 = requests.get(URL_3)\n",
    "                soup3 = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "                #print(soup.prettify())\n",
    "\n",
    "                #Now remove the script & then palce in files \n",
    "                for script in soup([\"script\", \"style\"]):\n",
    "                    script.extract()    # rip it out\n",
    "\n",
    "                # get text\n",
    "                text = soup.get_text()\n",
    "\n",
    "                # break into lines and remove leading and trailing space on each\n",
    "                lines = (line.strip() for line in text.splitlines())\n",
    "                # break multi-headlines into a line each\n",
    "                chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "                # drop blank lines\n",
    "                text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "                # convert into JSON:\n",
    "\n",
    "                fileName = new_URL3.replace('/','')\n",
    "\n",
    "                y = json.dumps(text)\n",
    "\n",
    "                with open(fileName + 'json_data.json', 'w') as outfile:\n",
    "                    outfile.write(y)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb57ad",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Below is some code for testing different attributes to get the correct links for each catergoy from the menu bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22f616aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"menu__link\" href=\"/developers/docs/\">Back to docs</a>\n",
      "<a aria-current=\"page\" class=\"menu__link menu__link--active\" href=\"/developers/docs/user-guides/\">User guides</a>\n",
      "<a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/basics/\">Getting to know Amplience</a>\n",
      "<a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/produce-content/\">Producing content</a>\n",
      "<a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/schedule-content/\">Scheduling content</a>\n",
      "<a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/assets/\">Managing assets</a>\n",
      "<a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/manage-accounts/\">Managing accounts</a>\n",
      "<a class=\"menu__link\" href=\"/developers/docs/user-guides/sso-single-sign-on/\">Single sign-on</a>\n",
      "<a aria-expanded=\"false\" class=\"menu__link menu__link--sublist menu__link--sublist-caret\" href=\"/developers/docs/user-guides/integrations/sfcc/\">Integrations</a>\n"
     ]
    }
   ],
   "source": [
    "# TODO - need to find a solution to grab every single URL within avaliable under Documentation\n",
    "# Menu bar holds most of the URLs\n",
    "\n",
    "for e in soup.body.findAll('ul', {'class':'theme-doc-sidebar-menu menu__list'}):\n",
    "    #print(e.findChildren())\n",
    "    for f in e.findAll('li'):\n",
    "        #print(f)\n",
    "        for g in f.findAll('a',{'class':'menu__link'}):\n",
    "            print(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c2d2ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"menu__list-item-collapsible\"><a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/basics/\">Getting to know Amplience</a><button aria-label=\"Toggle the collapsible sidebar category 'Getting to know Amplience'\" class=\"clean-btn menu__caret\" type=\"button\"></button></div>\n",
      "<div class=\"menu__list-item-collapsible\"><a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/produce-content/\">Producing content</a><button aria-label=\"Toggle the collapsible sidebar category 'Producing content'\" class=\"clean-btn menu__caret\" type=\"button\"></button></div>\n",
      "<div class=\"menu__list-item-collapsible\"><a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/schedule-content/\">Scheduling content</a><button aria-label=\"Toggle the collapsible sidebar category 'Scheduling content'\" class=\"clean-btn menu__caret\" type=\"button\"></button></div>\n",
      "<div class=\"menu__list-item-collapsible\"><a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/assets/\">Managing assets</a><button aria-label=\"Toggle the collapsible sidebar category 'Managing assets'\" class=\"clean-btn menu__caret\" type=\"button\"></button></div>\n",
      "<div class=\"menu__list-item-collapsible\"><a aria-expanded=\"false\" class=\"menu__link menu__link--sublist\" href=\"/developers/docs/user-guides/manage-accounts/\">Managing accounts</a><button aria-label=\"Toggle the collapsible sidebar category 'Managing accounts'\" class=\"clean-btn menu__caret\" type=\"button\"></button></div>\n",
      "<div class=\"menu__list-item-collapsible\"><a aria-expanded=\"false\" class=\"menu__link menu__link--sublist menu__link--sublist-caret\" href=\"/developers/docs/user-guides/integrations/sfcc/\">Integrations</a></div>\n"
     ]
    }
   ],
   "source": [
    "for e in soup.body.findAll('ul', {'class':'theme-doc-sidebar-menu menu__list'}):\n",
    "    for f in e.findAll('div'):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d049ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
